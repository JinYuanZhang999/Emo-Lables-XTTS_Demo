{
  "meta": {
    "title": "End-to-End Text-to-Speech With Emotion Label-Based Control",
    "authors": [
      "Danyang Cao",
      "Jinyuan Zhang"
    ],
    "institution": "School of Artificial Intelligence and Computer Science, North China University of Technology, Beijing, China 100144",
    "links": [
      { "name": "Code", "url": "https://github.com/JinYuanZhang999/Emo-Lables-XTTS" },
      { "name": "Model", "url": "https://huggingface.co/Jinyuan0910/Emo-Lables-XTTS/tree/main" },
      { "name": "Dataset", "url": "https://huggingface.co/datasets/Jinyuan0910/ELDB/tree/main" }
    ],
    "abstract": "Emotional expression plays a vital role in improving the naturalness and expressiveness of text-to-speech (TTS) systems. However, most existing emotional TTS approaches rely on emotional reference speech or emotion-labeled datasets with limited scale, which often leads to the entanglement of emotional information and speaker timbre, resulting in unstable emotion control. In this letter, we propose an emotion control method based on emotion labels and construct a high-quality emotion-labeled speech database, termed ELDB (Emotion-Labeled Database). By introducing emotion labels on the text side and employing neutral reference speech to represent speaker timbre, the proposed method effectively disentangles emotional characteristics from speaker identity. In addition, a two-stage fine-tuning strategy is adopted, together with an emotion consistency loss (ECL), to enhance the robustness of emotion control. Experimental results demonstrate that the proposed approach consistently outperforms the baseline system and existing emotional TTS methods in both subjective and objective evaluations, achieving improved emotional expressiveness while maintaining high speech naturalness and speaker consistency. Audio samples are available on the Emo-Labels-XTTS demo page.",
    "teaserImage": "assets/imgs/Model_architecture.png"
  },
  "experiments": [
    {
      "title": "Zero-Shot TTS with Emotionally Expressive Speech",
      "description": "To highlight the distinct control mechanism of our model compared to others, the reference audio and target synthesis text provided to the Proposed model differ from those of the other comparative models. The reference audio supplied to the Proposed model features the same speaker and content as that used for the other models, but it is a neutral, emotion-free audio sample. The target text provided to the Proposed model is the original text prefixed with an emotion label, for example: <Angry>He is a very humorous person.",
      "columns": ["Emotion", "Reference", "Baseline", "Mixed-Emotions","Emospeech","MED-TTS","Proposed"],
      "rows": [
        {
          "text": "Neutral",
          "audios": [
            "assets/audio/per_emo_best/Reference/neutral1_0020_000566.wav",
            "assets/audio/per_emo_best/Baseline/neutral1_0020_000566.wav",
            "assets/audio/per_emo_best/Mixed-Emotions/neutral1_0020_000566.wav",
            "assets/audio/per_emo_best/EmoSpeech/neutral1_0020_000566.wav",
            "assets/audio/per_emo_best/MED-TTS/neutral1_0020_000566.wav",
            "assets/audio/per_emo_best/Proposed/neutral1_0020_000566.wav"
          ]
        },
        {
          "text": "Neutral",
          "audios": [
            "assets/audio/per_emo_best/Reference/neutral2_0020_000581.wav",
            "assets/audio/per_emo_best/Baseline/neutral2_0020_000581.wav",
            "assets/audio/per_emo_best/Mixed-Emotions/neutral2_0020_000581.wav",
            "assets/audio/per_emo_best/EmoSpeech/neutral2_0020_000581.wav",
            "assets/audio/per_emo_best/MED-TTS/neutral2_0020_000581.wav",
            "assets/audio/per_emo_best/Proposed/neutral2_0020_000581.wav"
          ]
        },
        {
          "text": "Angry",
          "audios": [
            "assets/audio/per_emo_best/Reference/angry1_0020_000536.wav",
            "assets/audio/per_emo_best/Baseline/angry1_0020_000536.wav",
            "assets/audio/per_emo_best/Mixed-Emotions/angry1_0020_000536.wav",
            "assets/audio/per_emo_best/EmoSpeech/angry1_0020_000536.wav",
            "assets/audio/per_emo_best/MED-TTS/angry1_0020_000536.wav",
            "assets/audio/per_emo_best/Proposed/angry1_0020_000536.wav"
          ]
        },
        {
          "text": "Angry",
          "audios": [
            "assets/audio/per_emo_best/Reference/angry2_0020_000539.wav",
            "assets/audio/per_emo_best/Baseline/angry2_0020_000539.wav",
            "assets/audio/per_emo_best/Mixed-Emotions/angry2_0020_000539.wav",
            "assets/audio/per_emo_best/EmoSpeech/angry2_0020_000539.wav",
            "assets/audio/per_emo_best/MED-TTS/angry2_0020_000539.wav",
            "assets/audio/per_emo_best/Proposed/angry2_0020_000539.wav"
          ]
        },
        {
          "text": "Happy",
          "audios": [
            "assets/audio/per_emo_best/Reference/happy1_0020_000520.wav",
            "assets/audio/per_emo_best/Baseline/happy1_0020_000520.wav",
            "assets/audio/per_emo_best/Mixed-Emotions/happy1_0020_000520.wav",
            "assets/audio/per_emo_best/EmoSpeech/happy1_0020_000520.wav",
            "assets/audio/per_emo_best/MED-TTS/happy1_0020_000520.wav",
            "assets/audio/per_emo_best/Proposed/happy1_0020_000520.wav"
          ]
        },
        {
          "text": "Happy",
          "audios": [
            "assets/audio/per_emo_best/Reference/happy2_0020_000554.wav",
            "assets/audio/per_emo_best/Baseline/happy2_0020_000554.wav",
            "assets/audio/per_emo_best/Mixed-Emotions/happy2_0020_000554.wav",
            "assets/audio/per_emo_best/EmoSpeech/happy2_0020_000554.wav",
            "assets/audio/per_emo_best/MED-TTS/happy2_0020_000554.wav",
            "assets/audio/per_emo_best/Proposed/happy2_0020_000554.wav"
          ]
        },
        {
          "text": "Sad",
          "audios": [
            "assets/audio/per_emo_best/Reference/sad1_0020_000512.wav",
            "assets/audio/per_emo_best/Baseline/sad1_0020_000512.wav",
            "assets/audio/per_emo_best/Mixed-Emotions/sad1_0020_000512.wav",
            "assets/audio/per_emo_best/EmoSpeech/sad1_0020_000512.wav",
            "assets/audio/per_emo_best/MED-TTS/sad1_0020_000512.wav",
            "assets/audio/per_emo_best/Proposed/sad1_0020_000512.wav"
          ]
        },
        {
          "text": "Sad",
          "audios": [
            "assets/audio/per_emo_best/Reference/sad2_0020_000556.wav",
            "assets/audio/per_emo_best/Baseline/sad2_0020_000556.wav",
            "assets/audio/per_emo_best/Mixed-Emotions/sad2_0020_000556.wav",
            "assets/audio/per_emo_best/EmoSpeech/sad2_0020_000556.wav",
            "assets/audio/per_emo_best/MED-TTS/sad2_0020_000556.wav",
            "assets/audio/per_emo_best/Proposed/sad2_0020_000556.wav"
          ]
        },
        {
          "text": "Surprise",
          "audios": [
            "assets/audio/per_emo_best/Reference/surprise1_0020_000311.wav",
            "assets/audio/per_emo_best/Baseline/surprise1_0020_000311.wav",
            "assets/audio/per_emo_best/Mixed-Emotions/surprise1_0020_000311.wav",
            "assets/audio/per_emo_best/EmoSpeech/surprise1_0020_000311.wav",
            "assets/audio/per_emo_best/MED-TTS/surprise1_0020_000311.wav",
            "assets/audio/per_emo_best/Proposed/surprise1_0020_000311.wav"
          ]
        },
        {
          "text": "Surprise",
          "audios": [
            "assets/audio/per_emo_best/Reference/surprise2_0020_000542.wav",
            "assets/audio/per_emo_best/Baseline/surprise2_0020_000542.wav",
            "assets/audio/per_emo_best/Mixed-Emotions/surprise2_0020_000542.wav",
            "assets/audio/per_emo_best/EmoSpeech/surprise2_0020_000542.wav",
            "assets/audio/per_emo_best/MED-TTS/surprise2_0020_000542.wav",
            "assets/audio/per_emo_best/Proposed/surprise2_0020_000542.wav"
          ]
        }
      ]
    },
    {
      "title": "Zero-Shot TTS with Emotion Control Accuracy",
      "description": "To demonstrate the emotional control capability of our model, we synthesize five different emotions for the same text.",
      "columns": ["Reference", "Neutral", "Angry", "Happy","Sad","Surprise"],
      "rows": [
        {
          "audios": [
            "assets/audio/same_text/0020_000573_reference1.wav",
            "assets/audio/same_text/0020_000572_neutral.wav",
            "assets/audio/same_text/0020_000572_angry.wav",
            "assets/audio/same_text/0020_000572_happy.wav",
            "assets/audio/same_text/0020_000572_sad.wav",
            "assets/audio/same_text/0020_000572_surprise.wav"
          ]
        },
        {
          "audios": [
            "assets/audio/same_text/0020_000594_reference2.wav",
            "assets/audio/same_text/0020_000593_neutral.wav",
            "assets/audio/same_text/0020_000593_angry.wav",
            "assets/audio/same_text/0020_000593_happy.wav",
            "assets/audio/same_text/0020_000593_sad.wav",
            "assets/audio/same_text/0020_000593_surprise.wav"
          ]
        }
      ]
    }
  ]

}




